# POLARIS Framework Configuration
# =====================================
# This is the main configuration file for the POLARIS adaptive system framework.
# Keys here are flattened to environment variables by the ConfigurationManager
# (e.g. logger.name -> LOGGER_NAME). Keep only framework-level configurable
# settings. System/plugin-specific settings belong in the plugin `config.yaml`.
#
# Configuration Hierarchy:
# 1. Framework config (this file) - Core system settings
# 2. World Model config (world_model.yaml) - AI/ML model settings
# 3. Plugin configs (plugin/config.yaml) - System-specific settings
#
# Environment Variable Override Pattern:
# Any setting can be overridden using environment variables with uppercase,
# underscore-separated paths. Examples:
# - nats.url -> NATS_URL
# - logger.level -> LOGGER_LEVEL
# - digital_twin.grpc.port -> DIGITAL_TWIN_GRPC_PORT

# =============================================================================
# NATS Message Bus Configuration
# =============================================================================
# NATS is the central message bus for all inter-component communication in POLARIS.
# All adapters (Monitor, Execution) and the Digital Twin communicate through NATS.
#
# Performance Impact:
# - URL affects connection reliability and latency
# - Connection settings impact system resilience during network issues
# - Proper NATS configuration is critical for system performance
nats:
  # NATS server connection URL
  # Development: Use "nats://localhost:4222" for local development with default NATS
  # Production: Use clustered NATS with authentication: "nats://user:pass@nats-cluster:4222"
  # Docker: Use service name from docker-compose: "nats://nats:4222"
  # Security: For production, always use TLS: "tls://nats-cluster:4222"
  url: "nats://localhost:4222"

# =============================================================================
# Telemetry Data Flow Configuration
# =============================================================================
# Controls how monitoring data flows through the system from Monitor adapters
# to the Digital Twin and other consumers. Proper configuration balances
# real-time responsiveness with system performance.
#
# Data Flow: MonitorAdapter -> NATS -> DigitalTwin -> Analysis/Storage
telemetry:
  # NATS subject for streaming individual telemetry events
  # Used by MonitorAdapter.publish() for immediate event publishing
  # Higher frequency = more real-time but higher NATS load
  stream_subject: "polaris.telemetry.events.stream"
  
  # NATS subject for batched telemetry events
  # Used by MonitorAdapter batch publishing for efficiency
  # Reduces NATS message overhead for high-volume telemetry
  batch_subject: "polaris.telemetry.events.batch"
  
  # Maximum number of events per batch (triggers send when reached)
  # Development: 10-50 for faster feedback and easier debugging
  # Production: 100-500 for better throughput (balance with memory usage)
  # High-volume systems: 500-1000 (monitor memory consumption)
  batch_size: 100
  
  # Maximum wait time (seconds) before sending an incomplete batch
  # Lower values = more real-time but less efficient batching
  # Higher values = better batching but higher latency
  # Recommended: 0.5-2.0 seconds for most use cases
  batch_max_wait: 1.0
  
  # Maximum queue size for MonitorAdapter in-memory buffering
  # 0 = unbounded (risk of memory exhaustion under high load)
  # Recommended: 1000-10000 based on expected telemetry volume
  # Monitor memory usage and adjust based on system capacity
  queue_maxsize: 5000
  
  # Enable immediate streaming in addition to batching
  # true = Publish events both individually and in batches (higher load, more real-time)
  # false = Only batch publishing (more efficient, slightly higher latency)
  # Recommended: true for development, false for high-volume production
  stream: true
  
  # Knowledge Base configuration for telemetry storage
  # Enables local storage and aggregation of telemetry events
  knowledge_base:
    # Enable knowledge base storage of telemetry events
    enabled: true

    # Buffer size for raw telemetry events before aggregation
    # When buffer fills, events are aggregated into observations
    # Recommended: 100-200 based on metric frequency and memory constraints
    buffer_size: 100

# =============================================================================
# Execution Control Configuration
# =============================================================================
# Defines NATS subjects for control action flow between Digital Twin and
# Execution adapters. This enables the Digital Twin to send adaptation actions
# to managed systems and receive execution results.
#
# Data Flow: DigitalTwin -> NATS -> ExecutionAdapter -> ManagedSystem -> Results
execution:
  # NATS subject where control actions are published by Digital Twin
  # ExecutionAdapter listens on this subject for adaptation commands
  # Default: 'polaris.execution.actions' if omitted
  # Security: Consider using authenticated subjects in production
  action_subject: "polaris.execution.actions"
  
  # NATS subject where execution results are published by ExecutionAdapter
  # Digital Twin and other components can subscribe to track action outcomes
  # Used for feedback loops and adaptation effectiveness analysis
  result_subject: "polaris.execution.results"
  
  # NATS subject for execution-related performance metrics
  # Includes action latency, success rates, and execution adapter health
  # Useful for monitoring adaptation system performance
  metrics_subject: "polaris.execution.metrics"

# =============================================================================
# Logging Configuration
# =============================================================================
# Controls framework-wide logging behavior. Proper logging configuration is
# essential for debugging, monitoring, and production operations.
logger:
  # Logger name used by the framework (becomes LOGGER_NAME environment variable)
  # Used as the root logger name for all POLARIS framework components
  name: "polaris"
  
  # Logging level controls verbosity and performance
  # DEBUG: Detailed information for debugging (development only - high overhead)
  # INFO: General information about system operation (recommended for production)
  # WARNING: Warning messages and potential issues (minimal overhead)
  # ERROR: Only error messages (production troubleshooting)
  # Environment override: LOGGER_LEVEL
  level: "DEBUG"
  
  # Log output format affects readability and parsing
  # 'pretty': Colored, human-readable format (development, local debugging)
  # 'json': Structured JSON format (production, log aggregation systems)
  # Production recommendation: Use 'json' for centralized logging systems
  # Environment override: LOGGER_FORMAT
  format: "pretty"

# =============================================================================
# Digital Twin Configuration
# =============================================================================
# The Digital Twin is the core reasoning component that analyzes telemetry,
# maintains system models, and generates adaptation decisions. It integrates
# with World Models for AI-powered analysis and decision making.
#
# Architecture: NATS (messaging) + gRPC (API) + World Model (reasoning)
# Security Note: Digital Twin handles sensitive system data - secure all interfaces
digital_twin:
  # -------------------------------------------------------------------------
  # NATS Configuration for Digital Twin
  # -------------------------------------------------------------------------
  # Digital Twin subscribes to telemetry streams and publishes calibration
  # commands. It does NOT require adapters to publish to DT-specific topics.
  nats:
    # Subject for publishing update command to digital twin
    # Used when external system (for ex: Meta manager) needs to update the digital twin state
    update_subject: "polaris.digitaltwin.update"

    # Subject for publishing calibration commands to managed systems
    # Used when Digital Twin needs to trigger system recalibration
    calibrate_subject: "polaris.digitaltwin.calibrate"
    
    # Subject for Digital Twin error reporting and diagnostics
    # Other components can monitor Digital Twin health via this subject
    error_subject: "polaris.digitaltwin.errors"
    
    # NATS queue group for load balancing multiple Digital Twin instances
    # Enables horizontal scaling of Digital Twin processing
    # Production: Use meaningful names like "dt_prod_cluster"
    queue_group: "digital_twin_workers"
    
    # Connection resilience settings
    # Higher values = more resilient but longer recovery times
    max_reconnect_attempts: 10
    reconnect_wait_sec: 2
    
    # Internal message buffering for Digital Twin processing
    # Balance memory usage with processing capability
    queue_maxsize: 1000
    batch_size: 10
    batch_timeout_sec: 1.0
  
  # -------------------------------------------------------------------------
  # gRPC API Configuration
  # -------------------------------------------------------------------------
  # Provides external API for querying Digital Twin state and triggering
  # analysis. Used by external tools, dashboards, and integration systems.
  grpc:
    # Bind address for gRPC server
    # "0.0.0.0": Accept connections from any interface (development/container)
    # "127.0.0.1": Local connections only (security-focused deployment)
    # Production: Use specific interface IP for security
    host: "0.0.0.0"
    
    # gRPC server port
    # Standard: 50051 (default gRPC port)
    # Production: Use non-standard port + firewall rules for security
    # Docker: Ensure port is exposed in container configuration
    port: 50051
    
    # Maximum concurrent gRPC workers
    # Higher values = more concurrent API requests but more memory usage
    # Recommended: 2-4x CPU cores for CPU-bound workloads
    max_workers: 10
    
    # Maximum message size (bytes) for gRPC requests/responses
    # 4MB default handles most telemetry payloads
    # Increase for large batch queries or complex world model responses
    max_message_size: 4194304  # 4MB
    
    # Connection keepalive settings (milliseconds)
    # Prevents connection drops during long-running operations
    # Adjust based on network reliability and load balancer timeouts
    keepalive_time_ms: 30000      # Send keepalive every 30 seconds
    keepalive_timeout_ms: 5000    # Wait 5 seconds for keepalive response
  
  # -------------------------------------------------------------------------
  # World Model Integration
  # -------------------------------------------------------------------------
  # World Model provides AI/ML-powered reasoning capabilities for the Digital Twin.
  # See world_model.yaml for detailed World Model configuration.
  world_model:
    # World Model implementation type
    # "mock": Simple mock responses (development, testing)
    # "gemini": Google Gemini LLM-based reasoning (production AI)
    # "statistical": Time series and statistical analysis
    # "hybrid": Combines multiple approaches for robust reasoning
    implementation: "mock"
    
    # Path to World Model configuration file (relative to this config)
    # Contains implementation-specific settings for the selected World Model
    # IMPORTANT: This creates a dependency on world_model.yaml
    config_path: "mock_world_model.yaml"
    
    # Automatic reload on World Model failure
    # true: Attempt to reload World Model configuration on errors
    # false: Fail fast and require manual intervention
    # Production: Consider false for predictable behavior
    reload_on_failure: true
    
    # Health check interval for World Model monitoring (seconds)
    # Regular health checks ensure World Model responsiveness
    # Balance monitoring overhead with failure detection speed
    health_check_interval_sec: 60
  
  # -------------------------------------------------------------------------
  # Performance and Resource Management
  # -------------------------------------------------------------------------
  # Controls Digital Twin resource usage and response characteristics.
  # Tune based on system load, hardware capacity, and SLA requirements.
  performance:
    # Maximum concurrent queries to World Model
    # Higher values = better throughput but more resource usage
    # Consider World Model implementation limits (e.g., API rate limits)
    max_concurrent_queries: 10
    
    # Timeout for individual World Model queries (seconds)
    # Balance responsiveness with complex analysis requirements
    # Consider World Model processing time and network latency
    query_timeout_sec: 30
    
    # Timeout for simulation requests (seconds)
    # Simulations may require more time than simple queries
    # Adjust based on simulation complexity and accuracy requirements
    simulation_timeout_sec: 60
  
  # -------------------------------------------------------------------------
  # Debugging and Development Support
  # -------------------------------------------------------------------------
  # Enhanced logging and debugging features for development and troubleshooting.
  # Production: Disable detailed logging to reduce overhead and log volume.
  debugging:
    # Digital Twin specific log level (overrides framework logger.level)
    # Use DEBUG for development, INFO for production
    log_level: "DEBUG"
    
    # Enable detailed operation logging
    # Logs World Model interactions, decision processes, and timing
    # WARNING: High overhead - disable in production
    enable_detailed_logging: true
    
    # Output logs to console in addition to log files
    # Useful for development and container-based deployments
    log_to_console: true
    
    # Digital Twin specific log file path
    # Separate from framework logs for easier analysis
    # Ensure directory exists and has write permissions
    log_file: "logs/digital_twin.log"


# =============================================================================
# Security Considerations for Production Deployment
# =============================================================================
# CRITICAL: Review and implement these security measures before production use
#
# 1. Configuration Security:
#    - Store sensitive values in environment variables, not config files
#    - Use secrets management systems (Kubernetes secrets, HashiCorp Vault)
#    - Restrict file permissions on configuration files (600 or 640)
#    - Regularly rotate API keys and credentials
#
# 2. Logging Security:
#    - Avoid logging sensitive data (credentials, PII)
#    - Use structured logging with proper sanitization
#    - Secure log storage and transmission
#    - Implement log retention and rotation policies

# =============================================================================
# Environment-Specific Configuration Examples
# =============================================================================

# Development Environment Example:
# --------------------------------
# nats:
#   url: "nats://localhost:4222"
# logger:
#   level: "DEBUG"
#   format: "pretty"
# digital_twin:
#   world_model:
#     implementation: "mock"
#   debugging:
#     enable_detailed_logging: true
#   grpc:
#     host: "127.0.0.1"

# Production Environment Example:
# -------------------------------
# nats:
#   url: "tls://nats-prod-cluster:4222"
# logger:
#   level: "INFO"
#   format: "json"
# digital_twin:
#   world_model:
#     implementation: "gemini"
#   debugging:
#     enable_detailed_logging: false
#   grpc:
#     host: "10.0.1.100"  # Specific internal IP
#     port: 50051
#   performance:
#     max_concurrent_queries: 50

# Docker/Container Environment Example:
# ------------------------------------
# nats:
#   url: "nats://nats:4222"  # Use service name from docker-compose
# digital_twin:
#   grpc:
#     host: "0.0.0.0"  # Accept connections from container network
#   debugging:
#     log_to_console: true  # Container logs to stdout

# High-Volume Production Example:
# ------------------------------
# telemetry:
#   batch_size: 500
#   batch_max_wait: 2.0
#   queue_maxsize: 10000
#   stream: false  # Batch-only for efficiency
# digital_twin:
#   performance:
#     max_concurrent_queries: 100
#     query_timeout_sec: 60
#   nats:
#     queue_maxsize: 5000
#     batch_size: 50

# =============================================================================
# Configuration Interdependencies and Relationships
# =============================================================================
# Understanding how this configuration relates to other POLARIS config files:
#
# 1. World Model Dependency:
#    - digital_twin.world_model.config_path points to world_model.yaml
#    - Changes to World Model config may require Digital Twin restart
#    - World Model implementation choice affects performance settings
#
# 2. Plugin Configuration Relationship:
#    - Plugin configs (extern/*/config.yaml) define monitoring metrics
#    - Telemetry subjects must match between framework and plugin expectations
#    - Execution subjects enable Digital Twin to control plugin systems
#
# 3. Environment Variable Overrides:
#    - Any setting can be overridden via environment variables
#    - Use UPPERCASE with underscores: nats.url -> NATS_URL
#    - Environment overrides take precedence over file configuration
#
# 4. Schema Validation:
#    - This file is validated against framework_config.schema.json
#    - Schema changes require coordinated updates to this configuration
#    - Invalid configuration will prevent POLARIS startup
#
# 5. Logging Integration:
#    - Framework logger settings affect all POLARIS components
#    - Digital Twin debugging settings override framework logger for DT only
#    - Log file paths must be writable by POLARIS process user